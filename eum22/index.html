<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>7th EasyBuild User Meeting (24-28 Jan 2022)</title>
    <link rel="stylesheet" href="../stylesheets/styles.css">
    <link rel="stylesheet" href="../stylesheets/pygment_trac.css">
    <script src="../javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-21PF9ZVWWL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-21PF9ZVWWL');
</script>
</head>
<body>
    <div class="wrapper">
      <header>
        <h1 align="center"><img align="center" alt="EasyBuild" src="../images/easybuild_logo_small.png"/></h1><br/>
        <h3 align="center">7th EasyBuild User Meeting (24-28 Jan 2022, online)</h3>
      </header>
      <section>
        <p align="center">
        <img src="eum20_group_pic.png" alt="Group picture at 5th EasyBuild User Meeting (2020)"/>
        <span align="center"><em>(group picture from 5th EasyBuild User Meeting in Barcelona (Jan'20)</em></span>
        </p>
        <p>
        <a href="https://github.com/easybuilders/easybuild">EasyBuild</a> is a software build and installation framework
        that allows you to manage (scientific) software on High Performance Computing (HPC) systems in an efficient
        way.</p>
        <p>
        The <strong>EasyBuild User Meeting</strong> is an open and highly interactive event that provides a great opportunity
        to meet fellow EasyBuild enthusiasts, discuss related topics, and learn about new aspects of the tool.

        It is intended for people that are already familiar with EasyBuild, ranging from occasional users to
        EasyBuild core developers and experts, and topics will be less introductory in nature than during
        EasyBuild hackathons/workshops/tutorials that have been organized in the past.

        The program includes presentations by both EasyBuild users and developers,
        as well as talks about open source projects relevant to the EasyBuild community.
        </p>
<hr>

<p align="center">
<a href="#practical-info">Practical info</a> -
<a href="#registration">Registration</a> -
<a href="#organisation">Organisation</a> -
<strong>
<a href="#program">Program</a> -
</strong>
<a href="#contact">Contact</a>
</p>

<hr>

<a id="practical-info"/>
<h2><a>Practical information</a></h2>

<p>The 7th EasyBuild User Meeting will be held <strong>online</strong>,
during the week of <strong>Mon-Fri 24-28 Jan 2022.</strong></p>

<p><strong>Attendance is free of cost.</strong>
This is an open meeting, anybody interested is welcome to join.</p>

<h3>Zoom &amp; YouTube</h3>

<p>All presentations will be given <em>live</em> at the time listed in the program
via Zoom sessions, and live streaming will be available via the
<a href="https://www.youtube.com/c/easybuilders">EasyBuild YouTube channel</a>.
We intend to record all sessions, and will make the recordings available shortly after the live presentations.
</p>

<p>Attendees will be able to join Zoom sessions for interactive discussions with the speakers.<br/>
<strong>Note that only registered attendees will have access to the Zoom sessions!</strong></p>

<h3>Q&amp;A via <em>#eum</em> channel in EasyBuild Slack</h3>

<p>Next to raising questions or comments in the Zoom session,
you can also <strong>submit questions via the <a href="https://easybuild.slack.com/archives/CFM8FPQUQ">
<em>#eum</em> channel in the EasyBuild Slack</a></strong>.
Comments in YouTube will be disabled for the live streaming events.</p>

<p>If you are not logged in to the EasyBuild Slack yet, you can request an invitation to join
via <a href="https://easybuild.io/join-slack">https://easybuild.io/join-slack</a>.</p>

<hr>

<a id="registration"/>
<h2><a>Registration</a></h2>

<!--<p>If you plan to attend one or more presentations, we <strong>strongly encourage you to register</strong>.</p>

<p>Although attendance is free and open to anyone, having a good view on how well the different sessions will
be attended is important for us to be well prepared.</p>

<p><strong>To register your attendance, please visit:</strong></p>

<p align="center"><strong><a href="https://webappsx.ugent.be/eventManager/events/eumtwentytwo">
https://webappsx.ugent.be/eventManager/events/eumtwentytwo</a></strong></p>

<p>Updates and practical information will be sent via email to anyone who registered.</p>

<p>Registration will be open until Fri 21 Jan 2022.</p>
-->

<p><strong>Registration is closed</strong>, please follow the
<a href="https://www.youtube.com/c/easybuilders">YouTube live stream</a> (or contact <a
   href="mailto:eum@lists.ugent.be">eum@lists.ugent.be</a>).
</p>

<hr>

<a id="organisation"/>
<h2><a>Organisation</a></h2>

<p>
<ul>
    <li>Simon Branford (University of Birmingham, UK)</li>
    <li>Kenneth Hoste (HPC-UGent, Belgium)</li>
    <li>Alan O'Cais (CECAM)</li>
    <li>Åke Sandgren (Umeå University, Sweden)</li>
</ul>
</p>

<hr>

<a id="program"/>
<h2><a>Program</a></h2>

<p>The 7th EasyBuild User Meeting consists of several sessions spread over the week of 24-28 Jan 2022.

<strong>Please note that all times are in Universal Coordinated Time (UTC)!</strong></p>

<p>We intentionally left ample time in between talks to allow for Q&amp;A, interactive discussions, switching between speakers and breaks. </p>

<p>
Useful links:
<ul>
<li><a
        href="https://calendar.google.com/calendar/u/0?cid=YWowaTZzZ2E4amkzaWQxcmc1ZThwdHBjN2tAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">public
        Google calendar</a></li>
<li><a
        href="https://calendar.google.com/calendar/ical/aj0i6sga8ji3id1rg5e8ptpc7k%40group.calendar.google.com/public/basic.ics">downloadable calendar file in <em>.ics</em> format</a></li>

<li><a href="https://www.youtube.com/playlist?list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">YouTube playlist</a></li>

</ul></p>

<h3>Overview</h3>

<ul>

    <li style="list-style-type: none"><strong>Mon 24 Jan 2022</strong></li>
    <ul>
        <li><em>[15:45 UTC]</em> <a href="#welcome">Welcome to EUM'22</a></li>
        <li><em>[16:00 UTC]</em> <a href="#lumi">EasyBuild on LUMI, a pre-exascale supercomputer</a></li>
        <li><em>[17:00 UTC]</em> <a href="#eb-state-of-union">EasyBuild State of the Union</a></li>
    </ul>

    <li style="list-style-type: none"><strong>Tue 25 Jan 2022</strong></li>
    <ul>
        <li><em>[15:00 UTC]</em> <a href="#site-talks-tue">Site presentations: CECAM, BSC Earth Sciences, INUITS</a></li>
        <li><em>[16:00 UTC]</em> <a href="#cvmfs">CernVM-FS with Singularity/Apptainer: a great combination</a></li>
        <li><em>[17:00 UTC]</em> <a href="#apptainer">From Singularity to Apptainer</a></li>
        <li><em>[18:00 UTC]</em> <a href="#spack">The Spack 2022 Roadmap</a></li>
    </ul>

    <li style="list-style-type: none"><strong>Wed 26 Jan 2022</strong></li>
    <ul>
        <li><em>[14:00 UTC]</em> <a href="#spack-vs-eb">A noob test: Spack "vs" EasyBuild</a></li>
        <li><em>[15:00 UTC]</em> <a href="#eb-k8s">EasyBuild for Kubernetes-based Data Science Platforms</a></li>
        <li><em>[16:00 UTC]</em> <a href="#eb-mpi">Building a heterogeneous MPI stack with EasyBuild</a></li>
        <li><em>[17:00 UTC]</em> <a href="#eessi-getting-started">Getting started with EESSI</a></li>
        <li><em>[18:00 UTC]</em> <a href="#azure-eessi-wrf">Leveraging EESSI for WRF simulations at scale on Azure HPC</a></li>
    </ul>

    <li style="list-style-type: none"><strong>Thu 27 Jan 2022</strong></li>
    <ul>
        <li><em>[14:00 UTC]</em> <a href="#modules5">Modules 5</a></li>
        <li><em>[15:00 UTC]</em> <a href="#fusion">Simulating fusion plasmas</a></li>
        <li><em>[16:00 UTC]</em> <a href="#reframe">ReFrame update</a></li>
        <li><em>[17:00 UTC]</em> <a href="#lmod-xalt">Lmod and XALT: Updates</a></li>
        <li><em>[18:00 UTC]</em> <a href="#rse">The Research Software Engineer Movement</a></li>
    </ul>

    <li style="list-style-type: none"><strong>Fri 28 Jan 2022</strong></li>
    <ul>
        <li><em>[14:00 UTC]</em> <a href="#site-talks-fri">Site presentations: SURF, JSC</a></li>
        <li><em>[15:00 UTC]</em> <a href="#alphafold">AlphaFold: a new age for protein folding</a></li>
        <li><em>[16:00 UTC]</em> <a href="#eessi-workflow">Semi-automated workflow for adding software to EESSI</a></li>
        <li><em>[17:00 UTC]</em> <a href="#amd">AMD Instinct(tm) Accelerators and the ROCm(tm) Platform</a></li>
        <li><em>[18:00 UTC]</em> <a href="#riscv">Creating an Open HPC Ecosystem with RISC-V</a></li>
    </ul>

</ul>

<hr>

<a id="welcome"/></a>
<br/><p>
<em>[Mon 24 Jan 2022 - 15:45 UTC]</em><br/>
<strong>Welcome to EUM'22</strong>
<a href="https://www.youtube.com/watch?v=lVeDYF4k7no&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a> - 
<a href="000_eum22_welcome.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Kenneth Hoste (HPC-UGent, Belgium)</em>
</p>
<p>
Quick overview of agenda + practical guidelines for attending EUM'22.
</p><br/>

<hr>

<a id="lumi"/></a>
<br/><p>
<em>[Mon 24 Jan 2022 - 16:00 UTC]</em><br/>
<strong>EasyBuild on LUMI, a pre-exascale supercomputer</strong>
<a href="https://www.youtube.com/watch?v=hZezVG6lJNk&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube)</em></a>
- <a href="001_eum22_EasyBuild_on_LUMI.pdf"><em>slides, PDF)</em></a><br/>
<em>by Kurt Lust (University of Antwerp - Belgium + LUMI User Support Team)</em>
</p>
<p>
LUMI (<a href="https://lumi-supercomputer.eu">https://lumi-supercomputer.eu</a>) is one of the
EuroHPC JU pre-exascale systems. The supercomputer is hosted by a consortium of ten European countries,
led by Finland, and is in CSC's data centre in Kajaani, Finland. LUMI is an HPE-Cray EX system fully
based on AMD processor technology. Most of the compute power comes from 2,560 compute nodes with
four AMD MI250X GPUs, but the cluster also contains over 1,500 regular compute nodes, a partition for
data-analysis and visualization and a small cloud partition for containerized services. Storage
consists of 5 Lustre file systems (one flash-based and four with conventional hard disks) and an object
storage system. The cluster should have been fully built up by the end of 2021, but due to the global
component shortage the hardware installation is now expected to be finished by the end of April 2022.</p>

<p>The main programming environment on LUMI is the HPE-Cray Programming Environment with GNU,
Cray and AMD compilers. We are building our software stack on top of this using Lmod as the
module environment and EasyBuild as the primary tool for software installation. A key element of
LUMI is that it is run by a small central team as it is really meant to be a joint effort with local
support teams in the consortium countries. Hence the software stack and EasyBuild setup is designed
to empower the users and the local support teams and to make it easy to build on top of the centrally
installed software stack in a way that is as transparent as possible to the user.</p> 

<p>In this presentation we will give a short introduction to LUMI and to the way the support
organization is set up as LUMI is an interesting experiment to jointly operate a supercomputer
service with ten countries. Next we will tell how we got where we are today with EasyBuild on LUMI,
which is still an unfinished story as we are awaiting the finalization of the HPE-Cray programming
environment for AMD GPUs before we can fully assess what further developments we need to do into
EasyBuild to also install GPU software.
</p><br/>

<hr>

<a id="eb-state-of-union"/></a>
<br/><p>
<em>[Mon 24 Jan 2022 - 17:00 UTC]</em>
<strong>EasyBuild State of the Union</strong>
<a href="https://www.youtube.com/watch?v=B_mIkwzx9K8&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="002_eum22_state_of_the_union.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Kenneth Hoste (HPC-UGent, Belgium)</em>
</p>
<p>
Let's look back at what was changed in EasyBuild in the last year, how we are doing right now,
what we are currently working on, which challenges are ahead, and the enhancements and changes
in EasyBuild we envision for the future.</p>

<p>In addition, the highlights of the last EasyBuild User
Survey will be covered in this talk.
</p><br/>

<hr>

<a id="site-talks-tue"/></a>
<br/><p>
<em>[Tue 25 Jan 2022 - 15:00 UTC]</em><br/>
<strong>EasyBuild site presentations</strong>
<a href="https://www.youtube.com/watch?v=wuHWIx8Q2M0&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
(<em>recording @ YouTube</em></a>)<br/>
<ul>
    <li>CECAM (<em>by Alan O'Cais</em>)
        <a href="003_eum22_site_presentation_cecam.pdf"><em>(slides, PDF)</em></a></li>
    <li>BSC Earth Sciences (<em>by Kim Serradell</em>)
        <a href="004_eum22_site_presentation_bsc-earth-sciences.pdf"><em>(slides, PDF)</em></a></li>
    <li>INUITS (<em>Denis Kristak</em>)
        <a href="005_eum22_site_presentation_inuits.pdf"><em>(slides, PDF)</em></a></li>
</ul>
</p>
<p>
</p><br/>

<hr>

<a id="cvmfs"/></a>
<br/><p>
<em>[Tue 25 Jan 2022 - 16:00 UTC]</em><br/>
<strong>CernVM-FS with Singularity/Apptainer: a great combination</strong>
<a href="https://www.youtube.com/watch?v=oBo7LhOyK9M&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="006_eum22_cvmfs_singularity_apptainer.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Dave Dykstra (Fermilab, US)</em>
</p>
<p>
The CernVM-FileSystem (CVMFS) is ideal for transporting Singularity/
Apptainer "sandbox" style (unpacked) containers.  It moves metadata
operations to the client in the same performance-enhancing way as
monolithic SIF containers, while providing automatic updates and
enabling Singularity/Apptainer to run entirely unprivileged.</p>

<p>CERN
and OSG each host shared CVMFS repositories containing automatically
downloaded containers, which is especially efficient for storage and
network because CVMFS deduplicates repeated files.
A recent CVMFS feature enables publication of layered docker containers
to also be efficient, where the bulk of files shared in a large project's
software base can avoid the overhead of reprocessing.</p>

<p>I will
discuss my plans for incorporating that new feature in my
cvmfs-user-pub package which is designed to quickly make end user
software available worldwide to distributed batch processing.  I
will also discuss the challenges of using CVMFS on HPC systems and
the applicability of using my cvmfsexec package to run CVMFS
entirely as an end user without assistance from system
administrators.
</p><br/>

<hr>

<a id="apptainer"/></a>
<br/><p>
<em>[Tue 25 Jan 2022 - 17:00 UTC]</em><br/>
<strong>From Singularity to Apptainer</strong>
<a href="https://www.youtube.com/watch?v=elC6T60VgzM&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="007_eum22_apptainer.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Forrest Burt (Ctrl IQ, Inc.)</em>
</p>
<p>
Singularity, an open-source containerization platform built for high performance computing use cases and
utilized by HPC sites all over the world, was recently moved into the Linux Foundation and renamed to
"Apptainer" (<a href="https://apptainer.org">https://apptainer.org</a>).</p>

<p>This presentation will focus on exploring what this change means for Apptainer, including what the current
state of the project is, what the priorities for the project in the near-term are, and what the roadmap for
the future of the project looks like.
</p><br/>

<hr>

<a id="spack"/></a>
<br/><p>
<em>[Tue 25 Jan 2022 - 18:00 UTC]</em><br/>
<strong>The Spack 2022 Roadmap</strong>
<a href="https://www.youtube.com/watch?v=HyA7RpjoY1k&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="008_eum22_spack_2022_roadmap.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Todd Gamblin (LLNL, US)</em>
</p>
<p>
Recent updates to Spack include major rework of its dependency solving algorithm, developer environments, and
improvements to binary packaging. With the recent addition of --reuse, binary caches are far simpler to configure and
use, and Spack's oldest issue - too many rebuilds - is resolved.</p>
<p>This talk will cover recent developments and two major planned features for 2022 - compilers as dependencies and a
public binary cache. We'll talk about how we've built out Spack's package build CI to handle every pull request, how we
manage security, and how we expect to start providing binaries for core packages and compilers.
</p><br/>

<hr>

<a id="spack-vs-eb"></a>
<br/><p>
<em>[Wed 26 Jan 2022 - 14:00 UTC]</em><br/>
<strong>A noob test: Spack "vs" EasyBuild</strong>
<a href="https://www.youtube.com/watch?v=je7G1qWbpqk&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="009_eum22_spack_vs_easybuild.pdf"><em>slides, PDF)</em></a><br/>
<em>
    by Jan-Patrick Lehr (TU Darmstadt, Germany)</em>
</p>
<p>
Spack and EasyBuild promise to make software installation more accessible, if not easy.
This seems perfect to set up the dependencies for our own research software development.
The question is: how easy is it to get started with these systems?</p>

<p>I look at Spack and EasyBuild as package managers without any previous knowledge of either of the tools.
Our goal is to install the dependencies and toolchain for my C++ library MetaCG: GCC 9, Clang and LLVM 10,
Extra-P, cxxopts, nlohmann json, and several Python packages.</p>

<p>
Finally, creating a package file and an easy config for MetaCG is the ultimate achievement.
The talk will reflect on what I enjoyed about the package managers, what obstacles I ran into,
and which issues I encountered in my own software.
</p><br/>


<hr>

<a id="eb-k8s"/></a>
<br/><p>
<em>[Wed 26 Jan 2022 - 15:00 UTC]</em><br/>
<strong>EasyBuild for Kubernetes-based Data Science Platforms</strong>
<a href="https://www.youtube.com/watch?v=WGb5_ezhiPY&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="010_eum22_easybuild_k8s.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Guillaume Moutier (Red Hat)</em>
</p>
<p>
Kubernetes' agility, versatility, and resource scaling make it a great choice for shared data science
platforms in many organizations. However, data scientists often need to work with lots of different
libraries, languages, and applications, often with multiple versions. Conventional approaches, with a
legion of tailored images or a huge 20GB golden container image, don't match the reality of production.</p>

<p>In this presentation, we'll see how you can leverage EasyBuild with Open Data Hub, Red Hat's open source
data science project, to solve the challenges of synchronously managing multiple containers of different types,
making scientific libraries, languages and packages dynamically available in a simple way.
</p><br/>

<hr>

<a id="eb-mpi"/></a>
<br/><p>
<em>[Wed 26 Jan 2022 - 16:00 UTC]</em><br/>
<strong>Building a heterogeneous MPI stack with EasyBuild</strong>
<a href="https://www.youtube.com/watch?v=WPdcqFInXKY&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="011_eum22_mpi_easybuild.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Alex Domingo (Vrije Universiteit Brussel, Belgium)</em>
</p>
<p>
EasyBuild greatly simplifies the installation of several MPI implementations with a single command. However, the MPI
stack is tightly bound to the network hardware and directly interacts with kernel drivers and system libraries. Projects
such as OpenUCX and OpenFabrics aim at providing a unified driver to offload the network transport from the MPI
implementation. These higher-level drivers bring enhanced flexibility at runtime to MPI applications, as they can switch
the network interface on-the-fly. But the dependencies with hardware drivers and the host system are not pushed off the
table, just pushed down a larger library stack.</p>

<p>This problem is very hard to solve automagically in EasyBuild due to all factors at play that lie out of its control
(hardware configuration, build system, resource manager). Nonetheless, EasyBuild already provides tools to make custom
modifications to easyconfigs programmatically (e.g. hooks), which can be used to seamlessly build and deploy an MPI
stack fully adapted to your system. This talk will describe strategies to automatically handle the MPI stack with
OpenMPI and Intel MPI on TCP and InfiniBand networks, as well as with Nvidia GPUs. Selected configurations reflect what
we use at Vrije Universiteit Brussel in our heterogeneous tier-2 HPC.</p>
</p><br/>

<hr>

<a id="eessi-getting-started"/></a>
<br/><p>
<em>[Wed 26 Jan 2022 - 17:00 UTC]</em><br/>
<strong>Getting started with EESSI</strong>
<a href="https://www.youtube.com/watch?v=sreSIQHTGL8&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="012_eum22_getting_started_with_EESSI.pdf"><em>slides, PDF)</em></a><br/>
<em>Thomas Röblitz (Univ. of Bergen, Norway)</em>
</p>
<p>
The <a href="https://eessi.github.io/docs/">European Environment for Scientific Software Installations</a>
(EESSI, pronounced as "easy") is a collaborative project between different partners in HPC community, with
as common goal to build a common stack of scientific software installations for HPC systems and beyond,
including laptops, personal workstations and cloud infrastructure.</p>

<p>In this talk, we will outline how to get started with EESSI, from different angles:
<ul>
<li>a researcher who wants to employ EESSI on their personal (Linux) workstation, in the cloud,
    or on an HPC cluster;</li>
<li>a system adminstrator who wants to provide EESSI to end users;</li>
<li>a software developer who wants to leverage EESSI in a CI environment like GitHub Actions;</li>
</ul>
</p>

<p>We'll explain different ways of accessing EESSI, along with the requirements and tradeoffs,
so you're ready to hit the ground running once EESSI is ready for production use!
</p><br/>

<hr>

<a id="azure-eessi-wrf"/></a>
<br/><p>
<em>[Wed 26 Jan 2022 - 18:00 UTC]</em><br/>
<strong>Leveraging EESSI for WRF simulations at scale on Azure HPC</strong>
<a href="https://www.youtube.com/watch?v=LGkQi7BDf6w&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="013_eum22_WRF_Azure_EESSI.pdf"><em>slides, PDF)</em></a><br/>
<em>Hugo Meiland, Davide Vanzo (Microsoft Azure)</em>
</p>
<p>
<p>Fast and accurate high-resolution weather forecasting has become crucial to limit the impact on human
activities and population of weather events that are growing in frequency and intensity.<br/>

The timely simulation of large weather models requires computational resources that were typically attainable
only on large HPC clusters. The availability of HPC specific solutions on Azure allow any weather researcher
to access parallel computing at scale whenever needed.</p>

<p>The Weather Research and Forecasting (WRF) model is one of the most adopted open-source HPC software for
weather forecasting. The complexity of building the software stack required to run WRF also represents a
significant barrier for researchers.<br/>

In this talk we will explore how weather forecast community can leverage EESSI on Azure HBv3-series VMs
optimized for HPC applications to rapidly run WRF weather simulations at scale.</p>
</p><br/>

<hr>

<a id="modules5"/></a>
<br/><p>
<em>[Thu 27 Jan 2022 - 14:00 UTC]</em><br/>
<strong>Modules 5</strong>
<a href="https://www.youtube.com/watch?v=TXdfsWeeiBk&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="014_modules5.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Xavier Delaruelle (CEA)</em>
</p>
<p>
Modules, also called "Environment Modules", has turned 30 in 2021 and
is still there to help users dynamically managed their environment.
After 9 feature releases in the 4.x development cycle, Modules 5.0
was released last September. This talk will detail the prominent
features introduced during the last years and what is coming next for
2022.
</p><br/>

<hr>

<a id="fusion"/></a>
<br/><p>
<em>[Thu 27 Jan 2022 - 15:00 UTC]</em><br/>
<strong>Simulating fusion plasmas</strong>
<a href="https://www.youtube.com/watch?v=abU5Lrcrt5c&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="015_fusion.html">slides, HTML</a>)<br/>
<em>
by Thomas Hayward-Schneider (Max Planck Institute for Plasma Physics (IPP))</em>
</p>
<p>
Nuclear fusion, a promising but difficult future energy source, is actively being researched
with the huge international megaproject ITER due to become operational <em>soon</em> (this decade).
This talk will feature a brief introduction to nuclear fusion (no physics knowledge required).
It will discuss some of the methods used for modelling and simulating fusion plasmas, some of the
challenges faced, and new approaches being worked on (with an obvious bias towards the speaker's own
research topic).
</p><br/>

<hr>

<a id="reframe"/></a>
<br/><p>
<em>[Thu 27 Jan 2022 - 16:00 UTC]</em><br/>
<strong>ReFrame update</strong>
<a href="https://www.youtube.com/watch?v=FH5cHhhSdwI&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="016_reframe.pdf"><em>slides, PDF)</em></a><br/>
<em>
by Vasileios Karakasis (CSCS, Switzerland)</em>
</p>
<p>
<a href="http://reframe-hpc.readthedocs.io/">ReFrame</a> is a powerful framework for writing system regression
tests and benchmarks, specifically targeted to HPC
systems. The goal of the framework is to abstract away the complexity of the interactions with the system,
separating the logic of a test from the low-level details, which pertain to the system configuration and setup.
This allows users to write portable tests in a declarative way that describes only the test's functionality.</p>

<p>In this talk we will present the advancements in the framework since the last year and present a roadmap for
the upcoming months. We will also touch on the topic of reusability of tests across sites.
</p><br/>

<hr>

<a id="lmod-xalt"/></a>
<br/><p>
<em>[Thu 27 Jan 2022 - 17:00 UTC]</em><br/>
<strong>Lmod and XALT: Updates</strong>
<a href="https://www.youtube.com/watch?v=rdVgniPgQAQ&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>)
- <a href="017_lmod.pdf"><em>slides Lmod</em></a>, <a href="018_xalt.pdf"><em>slides XALT)</em></a><br/>
<em>
Robert McLay (TACC, US)</em>
</p>
<p>
<p>
<strong><a href="https://github.com/TACC/Lmod">Lmod</a></strong>
is the modern Environment Module Tool.  Sysadmins define packages
and let users choice which package and which version of that package.
This part of the talk will include a brief overview of Lmod. This
will be followed up with the new features such as module overview,
updates to sh_to_modulefile and sourcing shell scripts inside
modulefiles with source_sh() plus other recent changes to Lmod.</p>

<p>
<strong><a href="https://github.com/xalt/xalt">XALT</a></strong>
is a tool to take the census of what programs and libraries are
run on your cluster.  This talk will briefly cover what XALT does and
how it does it.  It will include some "war" stories of XALT
usage. Finally I'll cover recent changes to XALT. These include better
container support, a pre-ingestion filter, more compiler detection
(rust, chapel, etc) and better debugging support.
</p><br/>

<hr>

<a id="rse"/></a>
<br/><p>
<em>[Thu 27 Jan 2022 - 18:00 UTC]</em><br/>
<strong>The Research Software Engineer Movement</strong>
<a href="https://www.youtube.com/watch?v=FB2yV8TNnSw&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="019_rse.pdf"><em>slides, PDF)</em></a><br/>
<em>by Vanessa Sochat (LLNL, US)</em>
</p>
<p>
Research Software Engineers (RSEs) have been around for decades - we are graduate students
and postdocs that fell in love with writing software, or research support staff that strayed
from the traditional academic path and are committed to supporting research. However, we have
been hidden. It's only been in the last decade that we have started to find one another,
and form a strong community that offers to elevate and champion our role.</p>
<p>In this talk, I will tell the story of the RSE movement, starting from the UK and
spreading internationally to now what is a global movement. We will focus on events
from the past, different avenues for learning or getting involved, and hopes for the future.
Whether or not you are a research software engineer, you are also a part of this story and journey
toward having high quality software for sustainable, reproducible research.
</p><br/>

<hr>

<a id="site-talks-fri"/></a>
<br/><p>
<em>[Fri 28 Jan 2022 - 14:00 UTC]</em><br/>
<strong>EasyBuild site presentations</strong>
<a href="https://www.youtube.com/watch?v=RcW8NsRogm8&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>)<br/>
<ul>
    <li>SURF.nl (<em>by Maksim Masterov</em>)</li>
        <a href="020_eum22_site_presentation_surf.pdf"><em>(slides, PDF)</em></a></li>
    <li>JSC (<em>by Sebastian Achilles</em>)</li>
        <a href="021_eum22_site_presentation_jsc.pdf"><em>(slides, PDF)</em></a></li>
</ul>
</p>
<p>
</p><br/>

<hr>

<a id="alphafold"/></a>
<br/><p>
<em>[Fri 28 Jan 2022 - 15:00 UTC]</em><br/>
<strong>AlphaFold: a new age for protein folding</strong>
<a href="https://www.youtube.com/watch?v=iaU5vS0yYKE&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="022_eum22_alphafold.pdf"><em>slides, PDF)</em></a><br/>
<em>by Jasper Zuallaert (VIB-UGent, Belgium)</em>
</p>
<p>Proteins are essential biomolecules in all living organisms, performing various tasks from digestion to muscle
contraction to immune responses. A protein consists of amino acids chained together, and are often represented as a
one-dimensional sequence. However, protein function is often decided by the 3-D structure into which these chains
fold, rather than the sequence itself. Therefore, protein structure prediction from sequence information has been a
long-standing problem in biology.</p>

<p>In 2021, DeepMind released AlphaFold (v2), with which they won the international CASP14 structure prediction
competition in an overwhelming manner. Their deep-learning based solution was seen by several leading domain experts
as a once-in-a-lifetime breakthrough with a seemingly endless range of possible applications.</p>

<p>Given the high computational cost of deep learning algorithms, specialized hardware and software are required,
resulting
in a very high demand for availability and support on HPC systems. This presentation gives an outline of protein
folding, the impact of the AlphaFold release, and the software on the HPC.</p>
<br/>

<hr>

<a id="eessi-workflow"/></a>
<br/><p>
<em>[Fri 28 Jan 2022 - 16:00 UTC]</em><br/>
<strong>Semi-automated workflow for adding software to EESSI</strong>
<a href="https://www.youtube.com/watch?v=_qXc4uEJLr8&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="023_eum22_eessi_workflow.pdf"><em>slides, PDF)</em></a><br/>
<em>by Jörg Saßmannshausen (NIHR Biomedical Research Centre, UK)</em>
</p>
<p>
One major goal of European Environment for Scientific Software Installations (EESSI) collaborative project is
to let people propose software installations to include into EESSI, much like accepting contributions in
EasyBuild through pull requests.</p>

<p>The setup of EESSI, where optimized software installations for a diverse range of CPU microarchitectures
(Intel, AMD, Arm, POWER, and perhaps later also RISC-V), as well as the need to ensure a secure workflow,
makes this challenging.</br>
Other aspects of EESSI, like strictly controlling the build environment through containers, distributing
software via CernVM-FS, supporting different Linux distributions through a compatibility layer built with
Gentoo Prefix, and leveraging EasyBuild + Lmod for software installations and ReFrame for software testing,
actually make this feasible.</p>

<p>In this talk, we will outline our projected approach to this, which involves implementing a GitHub App
(in Python) that serves as a bot to help with processing pull requests to the easystack file that defines
the EESSI software layer.</p>

<p>The bot's tasks include testing software installations in the EESSI environment on all supported CPU
targets, (re-)running the tests for that software in different contexts (operating systems, platforms, etc.),
and eventually ingesting the software installations into EESSI, under the supervision of humans that review
the incoming contributions and assess the results produced by the bot.</p>

<p>Although our primary focus is to automate the contribution workflow in EESSI as much as possible, we believe
our GitHub App could also be useful beyond the EESSI project.
</p><br/>

<hr>

<a id="amd"/></a>
<br/><p>
<em>[Fri 28 Jan 2022 - 17:00 UTC]</em><br/>
<strong>AMD Instinct(tm) Accelerators and the ROCm(tm) Platform</strong>
<a href="https://www.youtube.com/watch?v=miE-TbjEAkI&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>)<br/>
<em>by Michael Klemm and Derek Bouius (AMD)</em>
</p>
<p>
With the Frontier and El Capitan systems on the horizon, ExaFLOP-sized systems have now become a reality.
These systems are and will be based on heterogeneous, accelerated platforms using AMD EPYC(tm) Processors
as well as AMD Instinct(tm) Accelerators.</p>
<p>In in the first part of this talk, we will review the node-level
design of the AMD Instinct(tm) MI200 Series GPUs.  We will cover key features of the GPU, such as the
AMD Infinity Fabric(tm) and review key performance metrics.  We will then briefly describe the GPU's
micro-architecture, how it is composed of compute units, and what their capabilities are.</p>
<p>In the second part,
we will discuss the AMD ROCm(tm) platform software stack that accompanies the AMD Instinct Accelerators and
show how it can be used to program for the AMD Processors and the AMD Instinct GPUs.  We will provide insight
into the individual components of the ROCm platform, build options, as well as containerization of GPU workloads.
We will allow amble time to ask questions and interact with the presenters.
</p><br/>

<hr>

<a id="riscv"/></a>
<br/><p>
<em>[Fri 28 Jan 2022 - 18:00 UTC]</em><br/>
<strong>Creating an Open HPC Ecosystem with RISC-V</strong>
<a href="https://www.youtube.com/watch?v=BVtwq_mmaXs&list=PLhnGtSmEGEQgCneeSQvYoIZrbv7wIKlo2">
<em>(recording @ YouTube</em></a>
- <a href="025_eum22_risc-v.pdf"><em>slides, PDF)</em></a><br/>
<em>by John D. Davis (Barcelona Supercomputing Centre)</em>
</p>
<p>
Over that last 3 decades, we have witnessed a transition from closed software ecosystems being the foundation
for HPC, enterprise, and business to open source software ecosystems based on Linux: from Arduino in the
IoT space, to Android in the mobile space, to Linux in HPC and cloud-based systems with various Open Source
Software projects built on top.</p>

<p>
However, when examining hardware, current commercial off the shelf solutions are closed hardware ecosystems
that only enable integration at the peripheral (PCIe) level. The combination of current technology trends,
the slowing of Moore's Law, and cost prohibitive silicon manufacturing inhibit significant power-performance
gains by relying on traditional closed ecosystems, especially in HPC, technology pushed to the extreme.
This new regime forces systems to be much more specialized to achieve the power-performance profiles required
for a supercomputer. In the past, HPC has led the way forward, defining the bleeding edge of technology.
HPC can do this again with open hardware, as it has done in software with adopting Linux and open source in
general. This is not only a technology imperative, but one born out of current geopolitics. Given this
technology and geopolitical backdrop, we describe how Europe can exploit its resources targeting
research and development for technological independence.</p>

<p>In this talk, first, we describe what RISC-V is. Next, using RISC-V as an instrument, provide a vision for
the future and a collection of current research and innovation projects, infrastructure, and the community
that are building the foundation for the future. This is a new opportunity for Europe to lead the way to an
HPC Future that is Wide Open!</p><br/>

<hr>

<a id="contact"/>
<h2><a>Contact</a></h2>

<p>In case of questions, please contact <a href="mailto:eum@lists.ugent.be">eum@lists.ugent.be</a>.</p>

<hr>

</section>
</div>
</body>
</html>
